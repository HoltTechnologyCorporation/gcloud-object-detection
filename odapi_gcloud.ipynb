{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "odapi_gcloud.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matz9x/gcloud-object-detection/blob/master/odapi_gcloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wcuPnBWHLPfn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Cloud object detection instance"
      ]
    },
    {
      "metadata": {
        "id": "8Bn7OV4p2_Vw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### License"
      ]
    },
    {
      "metadata": {
        "id": "eF8Bu0fT2-Ip",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The MIT License**\n",
        "\n",
        "Copyright (c) 2018  Mattia Varile\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "metadata": {
        "id": "7HRpyDkMivhg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Google Cloud Bucket structure"
      ]
    },
    {
      "metadata": {
        "id": "jGn4ECuoIbUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Google bucket internal structure should respect the following scheme:\n",
        "\n",
        "- {*name*}-detector-bucket\n",
        "    - model-{*net-model*}{*version*} \n",
        "        - data\n",
        "            - model.ckpt.index\n",
        "            - model.ckpt.meta\n",
        "            - model.ckpt.data-00000-of-00001\n",
        "            - pipeline.config\n",
        "            - label_map.pbtxt\n",
        "            - test.record\n",
        "            - train.record\n",
        "        - train\n",
        "        \n",
        "*name*: one-word to the define the project (e.g.: cloud, ship, house, ...) \n",
        "\n",
        "*net-model*: short neural network descriptor (e.g.: ssdmobilev2, ssdinceptionv3, yolo3, ...)\n",
        "\n",
        "*version*: model version (integer number)"
      ]
    },
    {
      "metadata": {
        "id": "fZ3_NvBfIryd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gcloud authentication"
      ]
    },
    {
      "metadata": {
        "id": "7ckUIgGslJom",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Authenticate yourself in order to access Google Cloud resources."
      ]
    },
    {
      "metadata": {
        "id": "tccO1hNTJYWd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Google cloud authentication"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lpkoyk2CIom2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KMzDcJYJJIRs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setting project in gcloud"
      ]
    },
    {
      "metadata": {
        "id": "gCQ88YQnqli_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setting the project name to use"
      ]
    },
    {
      "metadata": {
        "id": "2XwEWR77zXf3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gcloud config set project ship-detector-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gc7-JkoqI2GA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialization"
      ]
    },
    {
      "metadata": {
        "id": "9esPAZmSeLHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Installing ODAPI and setting up things\n",
        "\n",
        "%cd\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!apt-get install -qq protobuf-compiler python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive\n",
        "!pip install -q pycocotools\n",
        "!pip install -q gcloud\n",
        "\n",
        "%cd ~/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "##\n",
        "!python setup.py install\n",
        "!cp -r object_detection ../../../usr/local/lib/python3.6/dist-packages\n",
        "!cp -r slim/nets ../../../usr/local/lib/python3.6/dist-packages\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "%cd ../../../content\n",
        "!cp -r ~/models/research/object_detection /content\n",
        "##\n",
        "\n",
        "%cd ../root/models/research\n",
        "!bash object_detection/dataset_tools/create_pycocotools_package.sh /tmp/pycocotools\n",
        "!python setup.py sdist\n",
        "!(cd slim && python setup.py sdist)\n",
        "\n",
        "%cd ../../..\n",
        "!mkdir content/gpack\n",
        "!cp /tmp/pycocotools/pycocotools-2.0.tar.gz /content/gpack\n",
        "!cp root/models/research/slim/dist/slim-0.1.tar.gz /content/gpack\n",
        "!cp root/models/research/dist/object_detection-0.1.tar.gz /content/gpack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YT8q-c_FLxOS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing base model\n",
        "\n",
        "This cell will import baseline model from tensorflow/research website. This model will be used as initial status for the network for transfer learning.\n",
        "\n",
        "In the next cell please the baseline model name to use (find more: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)\n",
        "\n",
        "Once required, load *train.record*, *test.record* and *label_map.pbtxt* (loaded files should have the previously specified conventional names)"
      ]
    },
    {
      "metadata": {
        "id": "1NvK1DuIo4iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### INPUT START\n",
        "\n",
        "BASE_MODEL = 'ssdlite_mobilenet_v2_coco_2018_05_09'\n",
        "BUCKET_NAME = 'ship-detector-bucket'\n",
        "MODEL_NAME = 'model-ssdlitemobilev2-1'\n",
        "\n",
        "### INPUT END\n",
        "\n",
        "# Upload tfrecords\n",
        "%cd ../../..\n",
        "%cd content/gpack\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "print('Please upload: train.record | test.record | label_map.pbtxt')\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S5yfAU6-L1-w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_FILE = BASE_MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'baseline_model'\n",
        "\n",
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "data_path  = os.path.join('gs://', BUCKET_NAME, MODEL_NAME, 'data')\n",
        "train_path = os.path.join('gs://', BUCKET_NAME, MODEL_NAME, 'train')\n",
        "\n",
        "# Downloading base model from tensorflow website\n",
        "url = DOWNLOAD_BASE + MODEL_FILE\n",
        "filename = url.split(\"/\")[-1]\n",
        "with open(filename, \"wb\") as f:\n",
        "    r = requests.get(url)\n",
        "    f.write(r.content)\n",
        "\n",
        "# Extracting base model\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Cleaning up\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(BASE_MODEL, DEST_DIR)\n",
        "\n",
        "# Edit model config file\n",
        "filename = os.path.join(DEST_DIR, 'pipeline.config')\n",
        "with open(filename) as f:\n",
        "    s = f.read()\n",
        "with open(filename, 'w') as f:\n",
        "    s = re.sub('num_classes: 90', 'num_classes: 1', s)\n",
        "    s = re.sub('height: 300', 'height: 600', s)\n",
        "    s = re.sub('width: 300' , 'width: 600' , s)\n",
        "    s = re.sub('batch_size: 24' , 'batch_size: 16' , s)\n",
        "    s = re.sub('PATH_TO_BE_CONFIGURED/model.ckpt', \n",
        "               os.path.join(data_path, 'model.ckpt'), s)\n",
        "    s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_train.record', \n",
        "               os.path.join(data_path, 'train.tfrecord'), s)\n",
        "    s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_val.record', \n",
        "               os.path.join(data_path, 'test.tfrecord'), s)\n",
        "    s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt', \n",
        "               os.path.join(data_path, 'label_map.pbtxt'), s)\n",
        "    f.write(s)\n",
        "\n",
        "os.environ[\"data_path\"]  = data_path\n",
        "os.environ[\"train_path\"] = train_path\n",
        "\n",
        "# Uploading file to Gcloud\n",
        "!gsutil cp \"baseline_model/model.ckpt.*\" ${\"data_path\"}\n",
        "!gsutil cp \"baseline_model/pipeline.config\" ${\"data_path\"}\n",
        "!gsutil cp \"train.tfrecord\" ${\"data_path\"}\n",
        "!gsutil cp \"test.tfrecord\" ${\"data_path\"}\n",
        "!gsutil cp \"label_map.pbtxt\" ${\"data_path\"}\n",
        "\n",
        "# Define model variables to send to training command\n",
        "MODEL_DIR = os.path.join(BUCKET_NAME, MODEL_NAME, 'train')\n",
        "PIPELINE_CONFIG_PATH = os.path.join(BUCKET_NAME, MODEL_NAME, 'data/pipeline.config')\n",
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR\n",
        "os.environ[\"PIPELINE_CONFIG_PATH\"] = PIPELINE_CONFIG_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2habHVkI7rs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## YAML setting"
      ]
    },
    {
      "metadata": {
        "id": "5NVYUnrFn1rU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "YAML file is required by Google Cloud services in order to specify which hardware configuration to use (https://cloud.google.com/ml-engine/docs/tensorflow/training-jobs, https://cloud.google.com/ml-engine/docs/tensorflow/using-gpus)"
      ]
    },
    {
      "metadata": {
        "id": "3rehzKE4jMjk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### INPUT START\n",
        "\n",
        "s = \"\"\"trainingInput:\n",
        "    runtimeVersion: \"1.9\"\n",
        "    pythonVersion: \"2.7\"\n",
        "    scaleTier: CUSTOM\n",
        "    masterType: standard_gpu\n",
        "    workerCount: 1\n",
        "    workerType: standard_gpu\n",
        "    parameterServerCount: 1\n",
        "    parameterServerType: standard\"\"\"\n",
        "\n",
        "### INPUT END\n",
        "\n",
        "print(s)\n",
        "\n",
        "f = open(\"config.yaml\", \"w\")\n",
        "f.write(s)\n",
        "f.close()\n",
        "\n",
        "%cd ../../.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqYZ3fc20IyX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. A job with n workers will have n + 1 training machines (n workers + 1 master).\n",
        "2. The number of parameters servers used should be an odd number to prevent a parameter server from storing only weight variables or only bias variables (due to round robin parameter scheduling).\n",
        "3. The learning rate in the training config should be decreased when using a larger number of workers. Some experimentation is required to find the optimal learning rate."
      ]
    },
    {
      "metadata": {
        "id": "QXWmKD8tJPOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training initialization\n",
        "\n",
        "The following command starts the training procedure. A positive execution will display:\n",
        "\n",
        "\n",
        "```\n",
        "state: QUEUED\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "z7vj3HpKnddE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "PATH_TO_LOCAL_YAML_FILE=config.yaml\n",
        "gcloud ml-engine jobs submit training object_detection_`date +%m_%d_%Y_%H_%M_%S` \\\n",
        "    --runtime-version 1.9 \\\n",
        "    --job-dir=gs://${MODEL_DIR} \\\n",
        "    --packages object_detection-0.1.tar.gz,slim-0.1.tar.gz,pycocotools-2.0.tar.gz \\\n",
        "    --module-name object_detection.model_main \\\n",
        "    --region europe-west1 \\\n",
        "    --config ${PATH_TO_LOCAL_YAML_FILE} \\\n",
        "    -- \\\n",
        "    --model_dir=gs://${MODEL_DIR} \\\n",
        "    --pipeline_config_path=gs://${PIPELINE_CONFIG_PATH}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzcJidF9KGG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start tensorboard from terminal by executing the following command from terminal\n"
      ]
    },
    {
      "metadata": {
        "id": "0SYK02MlwRBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05ee19c9-f96e-430d-bb79-0d34bebf1ff3"
      },
      "cell_type": "code",
      "source": [
        "print(\"tensorboard --logdir=gs://\" + BUCKET_NAME + '/' + MODEL_NAME)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorboard --logdir=gs://ship-detector-bucket/model-ssdlitemobilev2-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dc7O3I_ygmnf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Interrupting job execution (PLEASE BE CAREFUL)\n",
        "!gcloud ml-engine jobs cancel object_detection_10_25_2018_11_36_10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gIQiwwyfKsFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# start streaming log by defining job name\n",
        "!gcloud ml-engine jobs stream-logs object_detection_10_25_2018_08_42_46"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXBncOtSw7Ya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exporting TF lite model (under development)"
      ]
    },
    {
      "metadata": {
        "id": "KYLnsDP4xay0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Installing bazel\n",
        "!apt-get install openjdk-8-jdk\n",
        "!echo \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list\n",
        "!curl https://bazel.build/bazel-release.pub.gpg | apt-key add -\n",
        "!apt-get update && apt-get install bazel\n",
        "!apt-get upgrade bazel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FVMRa6IXxAXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "export CONFIG_FILE=$PIPELINE_CONFIG_PATH\n",
        "export CHECKPOINT_PATH=$MODEL_DIR\n",
        "export OUTPUT_DIR=/tflite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KZIY0JGZ0-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd ../../..\n",
        "\n",
        "BUCKET_NAME = 'ship-detector-bucket'\n",
        "MODEL_NAME = 'model-ssdlitemobilev2-1'\n",
        "MODEL_DIR = os.path.join(BUCKET_NAME, MODEL_NAME, 'train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tk-Yom0t-VDF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download objects from google cloud\n",
        "\n",
        "%%bash\n",
        "mkdir content/gcloudfiles\n",
        "mkdir content/outputfiles\n",
        "gsutil cp gs://${MODEL_DIR}/model.* content/gcloudfiles\n",
        "gsutil cp gs://${MODEL_DIR}/pipeline.config content/gcloudfiles\n",
        "gsutil cp gs://${MODEL_DIR}/graph.pbtxt content/gcloudfiles\n",
        "export CHECKPOINT_PATH=content/gcloudfiles/model.ckpt-5382\n",
        "export CONFIG_FILE=content/gcloudfiles/pipeline.config\n",
        "export OUTPUT_DIR=content/outputfiles\n",
        "\n",
        "python content/object_detection/export_tflite_ssd_graph.py \\\n",
        "--pipeline_config_path=$CONFIG_FILE \\\n",
        "--trained_checkpoint_prefix=$CHECKPOINT_PATH \\\n",
        "--output_directory=$OUTPUT_DIR \\\n",
        "--add_postprocessing_op=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UCuf32ALKZYT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TOCO Converting process\n",
        "%%bash\n",
        "%cd ../../..\n",
        "touch WORKSPACE\n",
        "bazel run -c opt //usr/local/lib/python3.6/dist-packages/tensorflow/contrib/lite/toco:toco -- \\\n",
        "--input_file=$OUTPUT_DIR/tflite_graph.pb \\\n",
        "--output_file=$OUTPUT_DIR/detect.tflite \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=QUANTIZED_UINT8 \\\n",
        "--mean_values=128 \\\n",
        "--std_values=128 \\\n",
        "--change_concat_input_ranges=false \\\n",
        "--allow_custom_ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3vhu2h759ifT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python content/object_detection/export_tflite_ssd_graph.py \\\n",
        "--pipeline_config_path=$CONFIG_FILE \\\n",
        "--trained_checkpoint_prefix=$CHECKPOINT_PATH \\\n",
        "--output_directory=$OUTPUT_DIR \\\n",
        "--add_postprocessing_op=true"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}